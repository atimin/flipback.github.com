---
layout: post
title: "Перевод 'Machine Learning. Introduction.'"
date: 2012-08-12 15:58
comments: true
categories: [Russian, translations, meachine learning, math]
---

##От переводчика(меня).

Не так давно наткнулся на очень интересный ресурс [Math&Programming](http://jeremykun.wordpress.com/), который, как вы наверно догадались по названию, посвящен математике и программированию. И поскольку, мне самому очень интересна тема искусственного интеллекта, решил начать перевод серии постов посвященной машинному обучению. Таким образом, я надеюсь убить 2-х зайцев: разобраться в материале самому и подтянуть навыки технического перевода. Ну конечно, я очень надеюсь, что это будет еще кому-то полезно.

<!-- more -->

#Машинное обучение. Введение. 

Источник [Machine Learning — Introduction](http://jeremykun.wordpress.com/2012/08/04/machine-learning-introduction/)

##Серия постов о машинном обучении.

В наши дни существует ошеломляющее количество исследований и разработок в очень грубо определенной научной области под названием машинное обучение. Отчасти, она так грубо определена потому, что она занимает методы из многих других областей науки. Множество задач в машинном обучении могут быть сформулированы разными, но эквивалентными способами. Пока они являются обычной задачей оптимизации, такие методы могут быть выражены в терминах статистических условий, иметь биологическую интерпретацию или иметь отчетливо геометрический или топологический вид. Как результат, машинное обучение (далее МО) стало пониматься как набор методов, т.е. противоположно единой теории. 

Неудивительно, почему такое количество математики поддерживает эту диверсионную дисциплину. Практики (т.е. создатели алгоритмов) опираются  на статистику, линейную алгебру, выпуклую оптимизацию и интересуются теорией графов, функциональным анализом и топологией. Конечно, так или иначе, машинное обучение фокусируется на алгоритмах и данных. 

Основной шаблон, который мы будем видеть снова и снова, когда мы будем выводить и реализовывать различные методы, это разработка алгоритма или математической модели, тестирование результата на наборе данных, и улучшение модели, основанной на предметно-ориентированных знаниях. Первый шаг обычно включает в себя "прыжок веры", основанный на некой математической интуиции. Второй шаг - горсть надежных и хорошо понятых входных данных (часто взятых из [базы данных Университета Калифорнии или Ирвина](http://archive.ics.uci.edu/ml/) и существует некоторый спор какая из практик повсеместна). Третий шаг часто является настройкой "с бубном" алгоритма и входных данных, чтобы дополнить одно другим.

Автор убежден, что математический фундамент - это самая важная часть МО, которая отражается в эффективности деталей реализации алгоритма. Цель МО - это представить данные, взятые из реального мира и имеющие свойственную реальным объектам структуру, и использовать их; дать настоящий результат - нечто должно абстрактно анализировать и представлять данные. Таким образом, этот блог будет фокусироваться в основном на математику, лежащую в основе алгоритмов и структур данных. 

##Общий план

Пока мы намереваемся покрыть классический набор тем МО, такие как нейронные сети и дерева решений, мы хотели бы бегло показать более сложные современные методы, такие как метод опорных векторов (*suppot vector machines*) и методы основанные на Колмогоровской сложности. Итак, мы публикуем ниже честолюбивый список тем (в необязательном порядке):

  1. К-ближайших соседей
  2. Дерево решений
  3. Кластеризация по центру и по плотности
  4. Нейронные сети
  5. Метод опорных векторов
  6. Регрессия
  7. Байесовый вывод и сети
  8. Методы основанные на сложности Колмогорова
  9. Гомологии обучения и представления.

Этот длинное и окольное путешествие будет неизбежно требовать произвольно большой(но конечной!) математической базы. Мы будем касаться: метрического пространства, математического анализа, теории вероятности, абстрактной алгебры, топологии и даже теории категорий. Замете, что некоторые эзотерические (т.е. продвинутые) темы будут иметь также свою собственную серию. 

Конечно, как мы отмечали прежде, пока математики движимы желанием формализовывать  идеи,  программисты  мотивируются тем, что они могут сделать. Итак, мы заинтересованны использовать МО для выполнения крутых задач. Часть идей мы планируем реализовать в этом блоге: анализ социальных сетей, машинное зрение и распознавание текста, определение спама, обработка естественной речи, и классификация содержания и рекомендации.

В конце концов, нас интересует теоретическая граница того, чему можно научить компьютер. В стороне от практического использования, эта область изучения может потребовать от нас строго определения -что же значит "учить" машину. Эта область известна как [теория вычислительного обучения](http://www.machinelearning.ru/wiki/index.php?title=%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F), и полезно для этого будет посвятить типичные сложнотеоретические вопросы, типа: "Может ли это класс функций классификации стать обученным за [полиномиальное время](http://ru.wikipedia.org/wiki/%D0%9A%D0%BB%D0%B0%D1%81%D1%81_P)?". Дополнительно, это включает изучение теорий больше из области статистики, например "Вероятно-приближенная коррекция" модели. Мы планируем изучить каждую из таких моделей и подключить их к нашим исследованиям, когда они потребуются.

Пока все. 
